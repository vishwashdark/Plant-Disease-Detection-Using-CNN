{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting hmmlearn\n",
      "  Downloading hmmlearn-0.3.0-cp311-cp311-win_amd64.whl (123 kB)\n",
      "                                              0.0/123.6 kB ? eta -:--:--\n",
      "     -------------------------------------  122.9/123.6 kB 3.6 MB/s eta 0:00:01\n",
      "     -------------------------------------- 123.6/123.6 kB 2.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.10 in c:\\users\\sharm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from hmmlearn) (1.23.5)\n",
      "Requirement already satisfied: scikit-learn!=0.22.0,>=0.16 in c:\\users\\sharm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from hmmlearn) (1.2.2)\n",
      "Requirement already satisfied: scipy>=0.19 in c:\\users\\sharm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from hmmlearn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\sharm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn!=0.22.0,>=0.16->hmmlearn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\sharm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn!=0.22.0,>=0.16->hmmlearn) (3.1.0)\n",
      "Installing collected packages: hmmlearn\n",
      "Successfully installed hmmlearn-0.3.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install hmmlearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.14666666666666667\n",
      "Precision: 0.1056\n",
      "Recall: 0.14666666666666667\n",
      "F1-score: 0.12279069767441861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sharm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Impute missing values with mean\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train_imputed = imputer.fit_transform(X_train)\n",
    "X_test_imputed = imputer.transform(X_test)\n",
    "\n",
    "# Create and fit the Gaussian HMM model\n",
    "n_components = 2\n",
    "hmm_model = hmm.GaussianHMM(n_components=n_components, covariance_type=\"diag\", n_iter=100)\n",
    "hmm_model.fit(X_train_imputed)\n",
    "\n",
    "# Perform predictions on the test set\n",
    "predicted_states = hmm_model.predict(X_test_imputed)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_test, predicted_states)\n",
    "precision = precision_score(y_test, predicted_states, average='weighted')\n",
    "recall = recall_score(y_test, predicted_states, average='weighted')\n",
    "f1 = f1_score(y_test, predicted_states, average='weighted')\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from hmmlearn import hmm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Subject ID  MRI ID        Group  Visit  MR Delay M/F Hand  Age  EDUC  \\\n",
      "0             1       1  Nondemented      1         0   M    R   87    14   \n",
      "1             1       1  Nondemented      2       457   M    R   88    14   \n",
      "2             2       2     Demented      1         0   M    R   75    12   \n",
      "3             2       2     Demented      2       560   M    R   76    12   \n",
      "4             2       2     Demented      3      1895   M    R   80    12   \n",
      "..          ...     ...          ...    ...       ...  ..  ...  ...   ...   \n",
      "367         185     185     Demented      2       842   M    R   82    16   \n",
      "368         185     185     Demented      3      2297   M    R   86    16   \n",
      "369         186     186  Nondemented      1         0   F    R   61    13   \n",
      "370         186     186  Nondemented      2       763   F    R   63    13   \n",
      "371         186     186  Nondemented      3      1608   F    R   65    13   \n",
      "\n",
      "     SES  MMSE  CDR  eTIV   nWBV    ASF  \n",
      "0    2.0  27.0  0.0  1987  0.696  0.883  \n",
      "1    2.0  30.0  0.0  2004  0.681  0.876  \n",
      "2    0.0  23.0  0.5  1678  0.736  1.046  \n",
      "3    0.0  28.0  0.5  1738  0.713  1.010  \n",
      "4    0.0  22.0  0.5  1698  0.701  1.034  \n",
      "..   ...   ...  ...   ...    ...    ...  \n",
      "367  1.0  28.0  0.5  1693  0.694  1.037  \n",
      "368  1.0  26.0  0.5  1688  0.675  1.040  \n",
      "369  2.0  30.0  0.0  1319  0.801  1.331  \n",
      "370  2.0  30.0  0.0  1327  0.796  1.323  \n",
      "371  2.0  30.0  0.0  1333  0.801  1.317  \n",
      "\n",
      "[372 rows x 15 columns]\n"
     ]
    }
   ],
   "source": [
    "#Load the dataset\n",
    "data = pd.read_csv('C:/Users/sharm/OneDrive/Desktop/dementia_dataset.csv')\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Subject ID  MRI ID        Group  Visit  MR Delay M/F Hand  Age  EDUC  \\\n",
      "3             2       2     Demented      2     560.0   M    R   76    12   \n",
      "4             2       2     Demented      3    1895.0   M    R   80    12   \n",
      "8             5       5  Nondemented      2    1010.0   M    R   83    12   \n",
      "11            7       7     Demented      3     518.0   M    R   73    16   \n",
      "12            7       7     Demented      4    1281.0   M    R   75    16   \n",
      "..          ...     ...          ...    ...       ...  ..  ...  ...   ...   \n",
      "347         176     176    Converted      3    1631.0   M    R   89    16   \n",
      "354         179     179     Demented      2     652.0   M    R   81    20   \n",
      "365         184     184     Demented      2     553.0   F    R   73    16   \n",
      "367         185     185     Demented      2     842.0   M    R   82    16   \n",
      "368         185     185     Demented      3    2297.0   M    R   86    16   \n",
      "\n",
      "     SES  MMSE  CDR  eTIV   nWBV    ASF  \n",
      "3    0.0  28.0  0.5  1738  0.713  1.010  \n",
      "4    0.0  22.0  0.5  1698  0.701  1.034  \n",
      "8    4.0  29.0  0.5  1701  0.711  1.032  \n",
      "11   0.0  27.0  1.0  1365  0.727  1.286  \n",
      "12   0.0  27.0  1.0  1372  0.710  1.279  \n",
      "..   ...   ...  ...   ...    ...    ...  \n",
      "347  2.0  30.0  0.5  1408  0.679  1.246  \n",
      "354  1.0  26.0  0.5  1556  0.691  1.128  \n",
      "365  3.0  21.0  1.0  1351  0.708  1.299  \n",
      "367  1.0  28.0  0.5  1693  0.694  1.037  \n",
      "368  1.0  26.0  0.5  1688  0.675  1.040  \n",
      "\n",
      "[95 rows x 15 columns]\n"
     ]
    }
   ],
   "source": [
    "# Replace zeros in 'MR Delay' and 'CDR' columns with NaN\n",
    "data[['MR Delay', 'CDR']] = data[['MR Delay', 'CDR']].replace(0, np.nan)\n",
    "data.dropna(inplace=True)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Subject ID  MRI ID  Group  Visit  MR Delay  M/F  Hand  Age  EDUC  SES  \\\n",
      "3             2       2      1      2     560.0    1     0   76    12  0.0   \n",
      "4             2       2      1      3    1895.0    1     0   80    12  0.0   \n",
      "8             5       5      2      2    1010.0    1     0   83    12  4.0   \n",
      "11            7       7      1      3     518.0    1     0   73    16  0.0   \n",
      "12            7       7      1      4    1281.0    1     0   75    16  0.0   \n",
      "..          ...     ...    ...    ...       ...  ...   ...  ...   ...  ...   \n",
      "347         176     176      0      3    1631.0    1     0   89    16  2.0   \n",
      "354         179     179      1      2     652.0    1     0   81    20  1.0   \n",
      "365         184     184      1      2     553.0    0     0   73    16  3.0   \n",
      "367         185     185      1      2     842.0    1     0   82    16  1.0   \n",
      "368         185     185      1      3    2297.0    1     0   86    16  1.0   \n",
      "\n",
      "     MMSE  CDR  eTIV   nWBV    ASF  \n",
      "3    28.0  0.5  1738  0.713  1.010  \n",
      "4    22.0  0.5  1698  0.701  1.034  \n",
      "8    29.0  0.5  1701  0.711  1.032  \n",
      "11   27.0  1.0  1365  0.727  1.286  \n",
      "12   27.0  1.0  1372  0.710  1.279  \n",
      "..    ...  ...   ...    ...    ...  \n",
      "347  30.0  0.5  1408  0.679  1.246  \n",
      "354  26.0  0.5  1556  0.691  1.128  \n",
      "365  21.0  1.0  1351  0.708  1.299  \n",
      "367  28.0  0.5  1693  0.694  1.037  \n",
      "368  26.0  0.5  1688  0.675  1.040  \n",
      "\n",
      "[95 rows x 15 columns]\n"
     ]
    }
   ],
   "source": [
    "# Encode categorical columns\n",
    "label_encoder = LabelEncoder()\n",
    "data['Group'] = label_encoder.fit_transform(data['Group'])\n",
    "data['M/F'] = label_encoder.fit_transform(data['M/F'])\n",
    "data['Hand'] = label_encoder.fit_transform(data['Hand'])\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Subject ID  MRI ID  Visit  MR Delay  M/F  Hand  Age  EDUC  SES  MMSE  \\\n",
      "3             2       2      2     560.0    1     0   76    12  0.0  28.0   \n",
      "4             2       2      3    1895.0    1     0   80    12  0.0  22.0   \n",
      "8             5       5      2    1010.0    1     0   83    12  4.0  29.0   \n",
      "11            7       7      3     518.0    1     0   73    16  0.0  27.0   \n",
      "12            7       7      4    1281.0    1     0   75    16  0.0  27.0   \n",
      "..          ...     ...    ...       ...  ...   ...  ...   ...  ...   ...   \n",
      "347         176     176      3    1631.0    1     0   89    16  2.0  30.0   \n",
      "354         179     179      2     652.0    1     0   81    20  1.0  26.0   \n",
      "365         184     184      2     553.0    0     0   73    16  3.0  21.0   \n",
      "367         185     185      2     842.0    1     0   82    16  1.0  28.0   \n",
      "368         185     185      3    2297.0    1     0   86    16  1.0  26.0   \n",
      "\n",
      "     CDR  eTIV   nWBV    ASF  \n",
      "3    0.5  1738  0.713  1.010  \n",
      "4    0.5  1698  0.701  1.034  \n",
      "8    0.5  1701  0.711  1.032  \n",
      "11   1.0  1365  0.727  1.286  \n",
      "12   1.0  1372  0.710  1.279  \n",
      "..   ...   ...    ...    ...  \n",
      "347  0.5  1408  0.679  1.246  \n",
      "354  0.5  1556  0.691  1.128  \n",
      "365  1.0  1351  0.708  1.299  \n",
      "367  0.5  1693  0.694  1.037  \n",
      "368  0.5  1688  0.675  1.040  \n",
      "\n",
      "[95 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "# Split the data into features (X) and target (y)\n",
    "X = data.drop('Group', axis=1)\n",
    "y = data['Group']\n",
    "print(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3      1\n",
      "4      1\n",
      "8      2\n",
      "11     1\n",
      "12     1\n",
      "      ..\n",
      "347    0\n",
      "354    1\n",
      "365    1\n",
      "367    1\n",
      "368    1\n",
      "Name: Group, Length: 95, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianHMM(n_components=2, n_iter=100)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianHMM</label><div class=\"sk-toggleable__content\"><pre>GaussianHMM(n_components=2, n_iter=100)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GaussianHMM(n_components=2, n_iter=100)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and fit the Gaussian HMM model\n",
    "n_components = 2\n",
    "hmm_model = hmm.GaussianHMM(n_components=n_components, covariance_type=\"diag\", n_iter=100)\n",
    "hmm_model.fit(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5789473684210527\n",
      "Precision: 0.6423751686909581\n",
      "Recall: 0.5789473684210527\n",
      "F1-score: 0.606015037593985\n"
     ]
    }
   ],
   "source": [
    "# Perform predictions on the test set\n",
    "predicted_states = hmm_model.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_test, predicted_states)\n",
    "precision = precision_score(y_test, predicted_states, average='weighted')\n",
    "recall = recall_score(y_test, predicted_states, average='weighted')\n",
    "f1 = f1_score(y_test, predicted_states, average='weighted')\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted hidden states:\n",
      "[2 2 2 2 2 2 2 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from hmmlearn import hmm\n",
    "\n",
    "# Define the Gaussian HMM model\n",
    "model = hmm.GaussianHMM(n_components=3, covariance_type=\"full\")\n",
    "\n",
    "# Generate some sample data\n",
    "np.random.seed(42)\n",
    "X = np.concatenate([np.random.randn(100, 2),\n",
    "                    10 + np.random.randn(50, 2),\n",
    "                    np.random.randn(100, 2)])\n",
    " \n",
    "# Fit the model to the data\n",
    "model.fit(X)\n",
    "\n",
    "# Predict the hidden states for a new sequence\n",
    "X_test = np.random.randn(10, 2)\n",
    "hidden_states = model.predict(X_test)\n",
    "\n",
    "# Print the predicted hidden states\n",
    "print(\"Predicted hidden states:\")\n",
    "print(hidden_states)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "openai.api_key=\"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\"\n",
    "def chat_with_gpt(prompt):\n",
    "    # Call the OpenAI API to generate a response\n",
    "    response = openai.Completion.create(\n",
    "        engine='text-davinci-003',\n",
    "        prompt=prompt,\n",
    "        max_tokens=50,\n",
    "        temperature=0.7,\n",
    "        n=1,\n",
    "        stop=None,\n",
    "        top_p=1.0,\n",
    "        frequency_penalty=0.0,\n",
    "        presence_penalty=0.0\n",
    "    )\n",
    "\n",
    "    # Extract and return the generated response\n",
    "    reply = response.choices[0].text.strip()\n",
    "    return reply\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatGPT: If you think you may have dementia, it is important that you see a doctor for an accurate diagnosis. A diagnosis of dementia is usually made by a doctor or a specialist in memory disorders. The doctor will evaluate your condition through a physical and\n",
      "ChatGPT: ');\n",
      "        done();\n",
      "      });\n",
      "\n",
      "      server.listen(function (err) {\n",
      "        if (err) {\n",
      "          return done(err);\n",
      "        }\n",
      "\n",
      "        request(server)\n",
      "          .get('/')\n",
      "ChatGPT: from math import sqrt\n",
      "\n",
      "def factor(x):\n",
      "    factors = []\n",
      "    for i in range(1, int(sqrt(x)) + 1):\n",
      "        if x % i == 0:\n",
      "            factors.append\n",
      "ChatGPT: //\n",
      "//  HomeViewController.swift\n",
      "//  Zomato\n",
      "//\n",
      "//  Created by Anuj Doshi on 19/02/20.\n",
      "//  Copyright © 2020 Anuj Doshi. All rights reserved.\n",
      "ChatGPT: By\n",
      "\n",
      "Today’s top story: Is your retirement plan on track? Also in the news: How to create a budget in just 15 minutes, how to save on auto insurance, and an inside look at the basics of bitcoin.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[39m# Continue the conversation\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m----> 8\u001b[0m     user_input \u001b[39m=\u001b[39m \u001b[39minput\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39mYou: \u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      9\u001b[0m     \u001b[39mif\u001b[39;00m user_input\u001b[39m.\u001b[39mupper() \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mBYE\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m     10\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mChatGPT: Goodbye!\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py:1191\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m   1189\u001b[0m     msg \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1190\u001b[0m     \u001b[39mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[1;32m-> 1191\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_input_request(\n\u001b[0;32m   1192\u001b[0m     \u001b[39mstr\u001b[39;49m(prompt),\n\u001b[0;32m   1193\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_parent_ident[\u001b[39m\"\u001b[39;49m\u001b[39mshell\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m   1194\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_parent(\u001b[39m\"\u001b[39;49m\u001b[39mshell\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1195\u001b[0m     password\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m   1196\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py:1234\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m   1231\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   1232\u001b[0m     \u001b[39m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[0;32m   1233\u001b[0m     msg \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mInterrupted by user\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1234\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyboardInterrupt\u001b[39;00m(msg) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1235\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m   1236\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlog\u001b[39m.\u001b[39mwarning(\u001b[39m\"\u001b[39m\u001b[39mInvalid Message:\u001b[39m\u001b[39m\"\u001b[39m, exc_info\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "# Start the conversation\n",
    "user_input = input(\"You: \")\n",
    "response = chat_with_gpt(user_input)\n",
    "print(\"ChatGPT: \" + response)\n",
    "\n",
    "# Continue the conversation\n",
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    if user_input.upper() == \"BYE\":\n",
    "        print(\"ChatGPT: Goodbye!\")\n",
    "        break\n",
    "    response = chat_with_gpt(user_input)\n",
    "    print(\"ChatGPT: \" + response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
